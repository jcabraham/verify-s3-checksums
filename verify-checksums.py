#!/usr/bin/env python3

import glob
import hashlib
import logging
import signal
import sys

import click
import csv
import boto3


def sigint_handler():
    sys.exit(0)


signal.signal(signal.SIGINT, sigint_handler)

session = boto3.Session(profile_name='default')


def s3_dict(bucket, prefix):
    if not prefix.endswith('/'):
        prefix += '/'

    s3 = boto3.resource('s3')
    bucket = s3.Bucket(bucket)
    s3dict = {}

    s3iter = bucket.objects.filter(Delimiter='/', Prefix=prefix)
    for obj in s3iter:
        if not obj.key == prefix:
            key = obj.key.replace(prefix, '')
            etag = obj.e_tag.replace('\"', '')
            s3dict[key] = etag

    return s3dict


def hash_file(path):
    file_hash = hashlib.md5()

    with open(path, 'rb') as f:
        while chunk := f.read(8192):
            file_hash.update(chunk)

    return file_hash.hexdigest()


def verify_sums(s3dict, fn, local_sum, warn_missing):
    verified = False

    if fn not in s3dict:
        if warn_missing:
            print(f"WARNING {fn} not found in s3")
    else:
        s3_sum = s3dict[fn]

        if not s3_sum == local_sum:
            print(f"ERROR {fn} local: {local_sum} s3: {s3_sum}")
        else:
            logging.info(f"OK {fn} local: {local_sum}, s3: {s3_sum}")
            verified = True

    return verified


def set_log_level(debug):
    if debug:
        logging.basicConfig(format='%(message)s', level=logging.INFO)
    else:
        logging.basicConfig(format='%(message)s', level=logging.ERROR)


@click.group()
def cli():
    pass


@click.command(help="Read in a file list generated by md5sum and compare to sums on s3")
@click.option('--checksum-list', required=True, type=click.File('r'), help='Path to file containing output of md5sum *.')
@click.option('--bucket', required=True, help='Bucket name (e.g. "my-bucket", not "s3://my-bucket"')
@click.option('--remote-path', required=True, help='Bucket directory to check against, e.g. my-path/.')
@click.option('--warn-missing', required=False, is_flag=True, help='Warn if a file is missing from the bucket.')
@click.option('--debug', required=False, is_flag=True, help='Turn on debugging')
def check_list(checksum_list, bucket, remote_path, warn_missing, debug):
    set_log_level(debug)

    print(f"Verifying {checksum_list} checksums against s3://{bucket}/{remote_path}")
    print(f"Warn if files missing on s3: {warn_missing}")

    s3dict = s3_dict(bucket, remote_path)

    reader = csv.reader(checksum_list, delimiter=' ', quoting=csv.QUOTE_NONE)

    num_files = 0
    num_errors = 0

    for row in reader:
        num_files += 1
        fn = row[2]
        local_sum = row[0]
        verified = verify_sums(s3dict, fn, local_sum, warn_missing)
        if not verified:
            num_errors += 1

    print(f"Verified {num_files} files, {num_errors} errors.")


@click.command(help="Iterate over files in a directory, generate md5sum for each and compare to sum on s3")
@click.option('--local-path', type=click.Path(exists=True), help='Local directory path')
@click.option('--bucket', required=True, help='Bucket name (e.g. "my-bucket", not "s3://my-bucket"')
@click.option('--include', required=False, default="*", help='Glob of filenames to include, e.g. "*.gz". Defaults to "*" (all)')
@click.option('--remote-path', required=True, help='Bucket directory to check against, e.g. my-path/.')
@click.option('--warn-missing', required=False, is_flag=True, help='Warn if a file is missing from the bucket.')
@click.option('--debug', required=False, is_flag=True, help='Turn on debugging.')
def check_directory(local_path, bucket, include, remote_path, warn_missing, debug):
    set_log_level(debug)

    print(f"Verifying {local_path}/{include} checksums against s3://{bucket}/{remote_path}")
    print(f"Warn if files missing on s3: {warn_missing}")

    if not local_path.endswith('/'):
        local_path += '/'

    s3dict = s3_dict(bucket, remote_path)
    files = glob.glob(local_path + include)

    num_files = 0
    num_errors = 0

    for f in files:
        num_files += 1
        fn = f.replace(local_path, '')
        local_sum = hash_file(f)
        verified = verify_sums(s3dict, fn, local_sum, warn_missing)
        if not verified:
            num_errors += 1

    print(f"Verified {num_files} files, {num_errors} errors.")


cli.add_command(check_list)
cli.add_command(check_directory)

if __name__ == '__main__':
    cli()